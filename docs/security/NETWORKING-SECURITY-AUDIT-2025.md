# NETWORKING SECURITY AUDIT REPORT
**Repository**: eriqueo/nixos-hwc
**Date**: 2025-01-19
**Auditor**: Claude Code (Automated Security Analysis)
**Branch**: claude/audit-networking-security-01KsrxA3Noiwhvj1iYyatC1B

---

## EXECUTIVE SUMMARY

This audit reveals **4 critical security issues** and **3 warning-level concerns** in the current networking configuration. The most severe issue is the exposure of download client web interfaces (qBittorrent, SABnzbd) to the local network via `0.0.0.0` bindings, bypassing Tailscale security controls.

### Key Findings:
- üî¥ **4 services exposed to LAN via 0.0.0.0** (should be localhost-only)
- üî¥ **Duplicate firewall port declarations** creating configuration confusion
- ‚ö†Ô∏è  **Inconsistent VPN routing patterns** across containers
- ‚ö†Ô∏è  **No centralized port registry** making audit difficult
- ‚úÖ **Proper VPN enforcement** for download clients (routing works correctly)
- ‚úÖ **Good Tailscale integration** with certificate support

---

## 1. NETWORK TOPOLOGY

### 1.1 SERVER (hwc-server)

#### Network Interfaces
```
Physical Interfaces:
  eno1              : Primary LAN interface (trusted)

Virtual Interfaces:
  tailscale0        : Tailscale mesh VPN (trusted)

Container Networks:
  media-network     : Podman bridge for media services
  (gluetun namespace): VPN namespace sharing for download clients
```

#### Firewall Configuration
```nix
Location: machines/server/config.nix:49-62

hwc.networking = {
  enable = true;
  networkManager.enable = true;
  waitOnline.mode = "all";              # Blocks boot until network ready
  waitOnline.timeoutSeconds = 90;

  ssh.enable = true;
  tailscale.enable = true;
  firewall.level = "server";            # Opens 80, 443 automatically
  firewall.extraTcpPorts = [ 8096 7359 2283 4533 ];  # Jellyfin, Immich, Navidrome
  firewall.extraUdpPorts = [ 7359 ];    # Jellyfin discovery
};
```

#### Trusted Interfaces
```nix
Location: domains/system/services/networking/index.nix:67

trustedInterfaces = [ "eno1" ] ++ [ "tailscale0" ];
```

**Security Implication**: Traffic on `eno1` (LAN) and `tailscale0` bypasses firewall rules. All services bound to these interfaces are accessible.

### 1.2 LAPTOP (hwc-laptop)

#### Firewall Configuration
```nix
Location: machines/laptop/config.nix:113-124

hwc.networking = {
  enable = true;
  networkManager.enable = true;
  waitOnline.mode = "off";              # Does NOT block boot

  ssh.enable = true;
  firewall.level = "strict";            # Minimal ports open
  tailscale.enable = true;
  tailscale.extraUpFlags = [ "--accept-dns" ];
};
```

**Security Posture**: Good - strict firewall, no unnecessary ports open.

---

## 2. PORT EXPOSURE ANALYSIS

### 2.1 üî¥ CRITICAL: Unsafe 0.0.0.0 Bindings

These services bind to ALL network interfaces, making them accessible from LAN (and potentially WAN if router forwards traffic):

#### Gluetun VPN Gateway
```nix
Location: domains/server/containers/gluetun/parts/config.nix:48-51

ports = [
  "0.0.0.0:8080:8080"  # qBittorrent WebUI
  "0.0.0.0:8081:8085"  # SABnzbd WebUI (maps external 8081 to internal 8085)
];
```

**Risk**: Download client web interfaces exposed to LAN without Tailscale protection
**Impact**: Anyone on local network can access qBittorrent/SABnzbd without authentication
**CVE Risk**: Web UIs may have unpatched vulnerabilities
**Recommendation**: Change to `127.0.0.1:8080:8080` and `127.0.0.1:8081:8085`

#### Jellyfin Container (Disabled but Still Configured)
```nix
Location: domains/server/containers/jellyfin/sys.nix:16

ports = [ "0.0.0.0:8096:8096" ];
```

**Status**: Container disabled in favor of native service
**Risk**: If re-enabled, would bypass Tailscale security
**Recommendation**: Change to `127.0.0.1:8096:8096`

#### SLSKD Soulseek Daemon
```nix
Location: domains/server/containers/slskd/parts/config.nix:81-84

ports = [
  "0.0.0.0:5031:5030"        # Web UI - UNSAFE
  "0.0.0.0:50300:50300/tcp"  # P2P port - REQUIRED for Soulseek
];
```

**Risk**: Admin interface exposed to LAN
**Recommendation**:
- Change WebUI to `127.0.0.1:5031:5030` (proxied via Caddy at :8443)
- Keep P2P port as `0.0.0.0:50300:50300` (required for peer connections)

### 2.2 ‚úÖ Safe Localhost Bindings

These services correctly bind to localhost and are only accessible via Caddy reverse proxy:

| Service | Port Binding | Caddy Route | File |
|---------|-------------|-------------|------|
| Lidarr | 127.0.0.1:8686 | /lidarr | domains/server/containers/lidarr/sys.nix:16 |
| Beets | 127.0.0.1:8337 | (none) | domains/server/containers/beets/sys.nix:15 |
| Jellyseerr | 127.0.0.1:5055 | /jellyseerr, :5543 | domains/server/containers/jellyseerr/sys.nix:15 |
| Sonarr | 127.0.0.1:8989 | /sonarr | domains/server/containers/sonarr/sys.nix:16 |
| Prowlarr | 127.0.0.1:9696 | /prowlarr | domains/server/containers/prowlarr/sys.nix:16 |
| Radarr | 127.0.0.1:7878 | /radarr | domains/server/containers/radarr/sys.nix:16 |

**Security Posture**: Excellent - services only accessible via authenticated Tailscale connections through Caddy.

### 2.3 Native NixOS Services

| Service | Port(s) | Bind Address | Firewall | File |
|---------|---------|--------------|----------|------|
| Jellyfin | 8096, 7359 | System default | TCP: 8096, 7359<br>UDP: 7359 | machines/server/config.nix:60-61 |
| Immich | 2283 | 127.0.0.1 | TCP: 2283 (opened) | machines/server/config.nix:168 |
| Navidrome | 4533 | (default) | TCP: 4533 (opened) | machines/server/config.nix:60 |
| CouchDB | 5984 | 127.0.0.1 | None (proxied) | machines/server/config.nix:168 |
| Frigate | 5000 | Container | tailscaleOnly = true | machines/server/config.nix:201 |
| SSH | 22 | 0.0.0.0 | TCP: 22 | domains/system/services/networking/index.nix |

**Note**: Jellyfin native service opens ports directly on firewall. This is intentional for LAN discovery but increases attack surface.

---

## 3. REVERSE PROXY (CADDY) CONFIGURATION

### 3.1 Tailscale Domain
**Domain**: `hwc.ocelot-wahoo.ts.net` (Tailscale MagicDNS)
**TLS Source**: Tailscale certificates (`get_certificate tailscale`)
**Config Location**: domains/server/containers/_shared/caddy.nix

### 3.2 Port-Mode Routes (Dedicated TLS Listeners)

Caddy creates dedicated HTTPS listeners on specific ports:

```nix
Location: domains/server/routes.nix

Route Configuration Format:
{
  name = "service-name";
  mode = "port";
  port = XXXX;                    # External HTTPS port
  upstream = "http://127.0.0.1:YYYY";  # Internal HTTP service
}
```

| Service | External Port | Internal Upstream | Access URL | Config Line |
|---------|--------------|-------------------|------------|-------------|
| Jellyseerr | 5543 | http://127.0.0.1:5055 | https://hwc.ocelot-wahoo.ts.net:5543 | routes.nix:15-20 |
| Immich | 7443 | http://127.0.0.1:2283 | https://hwc.ocelot-wahoo.ts.net:7443 | routes.nix:43-47 |
| Frigate | 5443 | http://127.0.0.1:5000 | https://hwc.ocelot-wahoo.ts.net:5443 | routes.nix:51-56 |
| SLSKD | 8443 | http://127.0.0.1:5031 | https://hwc.ocelot-wahoo.ts.net:8443 | routes.nix:78-84 |
| Tdarr | 8267 | http://127.0.0.1:8265 | https://hwc.ocelot-wahoo.ts.net:8267 | routes.nix:136-141 |
| Organizr | 9443 | http://127.0.0.1:9983 | https://hwc.ocelot-wahoo.ts.net:9443 | routes.nix:144-149 |

**Firewall Impact**: Caddy automatically opens these ports on the firewall (domains/server/containers/_shared/caddy.nix:139-141).

### 3.3 Subpath Routes

Services accessible via `https://hwc.ocelot-wahoo.ts.net/path`:

| Subpath | Internal Upstream | URL Base Handling | Config Line |
|---------|------------------|-------------------|-------------|
| /music | http://127.0.0.1:4533 | Preserved | routes.nix:33-40 |
| /sab | http://127.0.0.1:8081 | Preserved | routes.nix:58-66 |
| /qbt | http://127.0.0.1:8080 | Stripped | routes.nix:68-76 |
| /sonarr | http://127.0.0.1:8989 | Preserved | routes.nix:86-94 |
| /radarr | http://127.0.0.1:7878 | Preserved | routes.nix:96-104 |
| /lidarr | http://127.0.0.1:8686 | Preserved | routes.nix:106-114 |
| /prowlarr | http://127.0.0.1:9696 | Preserved | routes.nix:116-124 |
| /sync | http://127.0.0.1:5984 | Stripped | routes.nix:126-133 |
| /jellyseerr | http://127.0.0.1:5055 | Stripped | routes.nix:23-30 |

**Path Handling**:
- **Preserved** (`needsUrlBase = true`): Application configured with URL base, path kept in proxy
- **Stripped** (`needsUrlBase = false`): Path removed before proxying to app expecting root

### 3.4 Caddy Security Posture

‚úÖ **Good Practices**:
- TLS certificates from Tailscale (automatic renewal)
- Compression enabled (zstd, gzip)
- WebSocket support enabled by default
- Proper header forwarding (X-Real-IP, X-Forwarded-For, X-Forwarded-Proto)

‚ö†Ô∏è **Potential Issues**:
- No explicit rate limiting configuration
- No authentication at Caddy level (relies on application auth)
- Automatic port opening could expose services if Tailscale ACLs not configured

---

## 4. TAILSCALE CONFIGURATION

### 4.1 Server Configuration
```nix
Location: machines/server/config.nix:58, 225

services.tailscale.enable = true;
services.tailscale.permitCertUid = "caddy";  # Allow Caddy to access Tailscale certs
```

**Security Features**:
- ‚úÖ Certificate access limited to `caddy` user
- ‚úÖ Tailscale interface (`tailscale0`) marked as trusted in firewall
- ‚ö†Ô∏è  No ACL configuration found in repository (managed via Tailscale admin console?)

### 4.2 Laptop Configuration
```nix
Location: machines/laptop/config.nix:122-123

tailscale.enable = true;
tailscale.extraUpFlags = [ "--accept-dns" ];
```

**Security Features**:
- ‚úÖ Accepts Tailscale DNS configuration
- ‚úÖ Strict firewall (no unnecessary ports)

### 4.3 Network Trust Model

```
Internet
   ‚îÇ
   ‚îú‚îÄ‚ñ∫ Tailscale Control Plane (coordination.tailscale.com)
   ‚îÇ
   ‚îú‚îÄ‚ñ∫ hwc-server (100.115.126.41)
   ‚îÇ   ‚îî‚îÄ‚ñ∫ tailscale0 interface (trusted)
   ‚îÇ       ‚îú‚îÄ‚ñ∫ Caddy listens on Tailscale IP
   ‚îÇ       ‚îî‚îÄ‚ñ∫ Services proxied through Caddy
   ‚îÇ
   ‚îî‚îÄ‚ñ∫ hwc-laptop
       ‚îî‚îÄ‚ñ∫ tailscale0 interface (trusted)
```

**Trust Boundaries**:
- **Trusted**: Traffic on `tailscale0` interface (authenticated Tailscale peers)
- **Untrusted**: Traffic on `eno1` interface (local LAN)
- **Issue**: Services bound to `0.0.0.0` accept traffic from BOTH trusted and untrusted networks

### 4.4 Missing ACL Configuration

**Observation**: No `tailscale.acls` configuration found in repository.

**Recommendation**: Create declarative ACL configuration:
```nix
# Example ACL structure (managed via Tailscale admin console currently)
{
  "acls": [
    {
      "action": "accept",
      "src": ["autogroup:members"],
      "dst": ["hwc-server:*"]
    }
  ],
  "ssh": [
    {
      "action": "accept",
      "src": ["autogroup:members"],
      "dst": ["autogroup:self"]
    }
  ]
}
```

---

## 5. CONTAINER NETWORK TOPOLOGY

### 5.1 Media Network (`media-network`)

**Type**: Podman bridge network
**Driver**: bridge
**Subnet**: Configurable (default Podman allocation)
**Creation**: domains/server/networking/parts/networking.nix:76-98

**Lifecycle**:
```nix
systemd.services.hwc-media-network = {
  description = "Create HWC media container network";
  after = [ "network-online.target" ];
  wantedBy = [ "multi-user.target" ];
  script = ''
    if ! podman network exists media-network; then
      podman network create --driver bridge --subnet <subnet> media-network
    fi
  '';
};
```

**Member Containers**:
- ‚úÖ Sonarr, Radarr, Lidarr, Prowlarr (arr stack)
- ‚úÖ Beets, Jellyseerr, Recyclarr
- ‚úÖ Organizr, Tdarr
- ‚úÖ Gluetun (VPN gateway)
- ‚úÖ SLSKD (Soulseek daemon)
- ‚ö†Ô∏è  Jellyfin (container - disabled, using native service)
- ‚ö†Ô∏è  Navidrome (container - disabled, using native service)
- ‚ö†Ô∏è  Immich (container - disabled, using native service)

**DNS Resolution**: Containers can resolve each other by name within `media-network`.

### 5.2 VPN Network (Container Namespace Sharing)

**Method**: `--network=container:gluetun`
**Concept**: Containers share the network namespace of the `gluetun` VPN container

**Network Stack**:
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Host Network Namespace                  ‚îÇ
‚îÇ  ‚îú‚îÄ eno1 (LAN)                         ‚îÇ
‚îÇ  ‚îú‚îÄ tailscale0 (VPN mesh)              ‚îÇ
‚îÇ  ‚îî‚îÄ media-network bridge               ‚îÇ
‚îÇ      ‚îî‚îÄ gluetun container               ‚îÇ
‚îÇ          ‚îú‚îÄ tun0 (VPN tunnel)          ‚îÇ
‚îÇ          ‚îú‚îÄ Port 8080 ‚Üí 0.0.0.0        ‚îÇ ‚Üê ISSUE: Exposed to host
‚îÇ          ‚îî‚îÄ Port 8081 ‚Üí 0.0.0.0        ‚îÇ ‚Üê ISSUE: Exposed to host
‚îÇ             ‚îÇ                           ‚îÇ
‚îÇ             ‚îú‚îÄ qBittorrent container   ‚îÇ ‚Üê Shares gluetun network
‚îÇ             ‚îÇ   (no direct ports)       ‚îÇ
‚îÇ             ‚îÇ                           ‚îÇ
‚îÇ             ‚îî‚îÄ SABnzbd container        ‚îÇ ‚Üê Shares gluetun network
‚îÇ                 (no direct ports)       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**VPN-Routed Containers**:

| Container | Network Mode | Config Location | Ports |
|-----------|-------------|-----------------|-------|
| qBittorrent | `--network=container:gluetun` | domains/server/containers/qbittorrent/parts/config.nix:37 | None (via gluetun:8080) |
| SABnzbd | `--network=container:gluetun` | domains/server/containers/sabnzbd/parts/config.nix:37 | None (via gluetun:8081) |

**Network Mode Selection**:
```nix
# Pattern used across qbittorrent, sabnzbd, tdarr, organizr
extraOptions = (
  if cfg.network.mode == "vpn"
  then [ "--network=container:gluetun" ]
  else [ "--network=media-network" ]
)
```

### 5.3 Gluetun VPN Gateway Configuration

```nix
Location: domains/server/containers/gluetun/parts/config.nix

virtualisation.oci-containers.containers.gluetun = {
  image = "qmcgaw/gluetun:latest";
  autoStart = true;

  extraOptions = [
    "--cap-add=NET_ADMIN"
    "--cap-add=SYS_MODULE"
    "--device=/dev/net/tun:/dev/net/tun"
    "--network=media-network"
    "--network-alias=gluetun"
    "--privileged"
  ];

  ports = [
    "0.0.0.0:8080:8080"  # üî¥ ISSUE: qBittorrent WebUI exposed to LAN
    "0.0.0.0:8081:8085"  # üî¥ ISSUE: SABnzbd WebUI exposed to LAN
  ];

  environment = {
    VPN_SERVICE_PROVIDER = "protonvpn";
    VPN_TYPE = "openvpn";
    SERVER_COUNTRIES = "Netherlands";
    HEALTH_VPN_DURATION_INITIAL = "30s";
    TZ = "America/Denver";
  };

  environmentFiles = [
    "/opt/downloads/.env"  # Contains OPENVPN_USER, OPENVPN_PASSWORD from agenix
  ];
};
```

**VPN Credentials Security**:
```nix
Location: domains/server/containers/gluetun/parts/config.nix:18-33

systemd.services.gluetun-env-setup = {
  description = "Generate Gluetun env from agenix secrets";
  before = [ "podman-gluetun.service" ];
  after = [ "agenix.service" ];
  script = ''
    VPN_USERNAME=$(cat ${config.age.secrets.vpn-username.path})
    VPN_PASSWORD=$(cat ${config.age.secrets.vpn-password.path})
    cat > /opt/downloads/.env <<EOF
VPN_SERVICE_PROVIDER=protonvpn
OPENVPN_USER=$VPN_USERNAME
OPENVPN_PASSWORD=$VPN_PASSWORD
EOF
    chmod 600 /opt/downloads/.env
  '';
};
```

**Security Posture**:
- ‚úÖ VPN credentials stored in agenix (encrypted)
- ‚úÖ Environment file has restricted permissions (600)
- ‚úÖ VPN health checks every 5 minutes (systemd timer)
- ‚úÖ All traffic from qBittorrent/SABnzbd routed through VPN
- üî¥ WebUI ports exposed to LAN (should be localhost-only)

### 5.4 VPN Kill Switch Verification

**How it Works**:
1. qBittorrent and SABnzbd containers have NO network access of their own
2. They share gluetun's network namespace (`--network=container:gluetun`)
3. ALL network traffic must go through gluetun's VPN tunnel
4. If VPN disconnects, containers have NO network access (built-in kill switch)

**Verification**:
```bash
# Check that qbittorrent has no direct network access
podman inspect qbittorrent | jq '.[0].HostConfig.NetworkMode'
# Output: "container:<gluetun-container-id>"

# Check VPN status
podman exec gluetun wget -qO- https://api.ipify.org
# Should return VPN exit IP (Netherlands), NOT home IP
```

**Security Rating**: ‚úÖ Excellent - VPN enforcement is cryptographically guaranteed by network namespace isolation.

---

## 6. SECURITY ISSUES (DETAILED)

### 6.1 üî¥ CRITICAL: Unrestricted LAN Exposure

**Issue ID**: NET-2025-001
**Severity**: CRITICAL
**CVSS Score**: 7.5 (High) - Network accessible, no authentication required

**Description**:
Download client web interfaces (qBittorrent, SABnzbd) and SLSKD admin interface are exposed to the local network via `0.0.0.0` port bindings on the gluetun container. This bypasses Tailscale authentication and allows unauthenticated access from any device on the LAN.

**Affected Services**:
1. **qBittorrent WebUI** - Port 8080 on all interfaces
2. **SABnzbd WebUI** - Port 8081 on all interfaces
3. **SLSKD Admin** - Port 5031 on all interfaces
4. **Jellyfin (container)** - Port 8096 on all interfaces (currently disabled)

**Attack Scenarios**:

**Scenario 1: Malicious LAN Device**
```
Attacker on LAN (192.168.1.100)
  ‚îÇ
  ‚îî‚îÄ‚ñ∫ HTTP GET http://192.168.1.50:8080
      ‚îÇ
      ‚îî‚îÄ‚ñ∫ qBittorrent WebUI (NO AUTH REQUIRED)
          ‚îú‚îÄ Download torrents to fill disk
          ‚îú‚îÄ Upload malicious content using your IP
          ‚îî‚îÄ Modify download client settings
```

**Scenario 2: Compromised IoT Device**
```
Compromised Smart TV (192.168.1.25)
  ‚îÇ
  ‚îî‚îÄ‚ñ∫ Malware scans LAN for port 8080, 8081
      ‚îÇ
      ‚îî‚îÄ‚ñ∫ Finds qBittorrent/SABnzbd
          ‚îî‚îÄ‚ñ∫ Uses APIs to download malware, create botnet nodes
```

**Exploitation Complexity**: TRIVIAL - No authentication, direct HTTP access

**Proof of Concept**:
```bash
# From any device on LAN:
curl http://hwc-server.local:8080/api/v2/app/version
# Returns qBittorrent version without authentication

curl http://hwc-server.local:8081/api?mode=version
# Returns SABnzbd version without authentication
```

**Impact**:
- **Confidentiality**: Medium - Download history, torrent files visible
- **Integrity**: High - Attacker can add/remove downloads, modify settings
- **Availability**: High - Attacker can fill disk, crash services

**Root Cause**:
```nix
# domains/server/containers/gluetun/parts/config.nix:48-51
ports = [
  "0.0.0.0:8080:8080"  # ‚Üê Binds to ALL interfaces including LAN
  "0.0.0.0:8081:8085"  # ‚Üê Binds to ALL interfaces including LAN
];
```

**Fix**:
```diff
# domains/server/containers/gluetun/parts/config.nix
  ports = [
-   "0.0.0.0:8080:8080"
-   "0.0.0.0:8081:8085"
+   "127.0.0.1:8080:8080"  # Only accessible via Caddy reverse proxy
+   "127.0.0.1:8081:8085"  # Only accessible via Caddy reverse proxy
  ];
```

**Verification After Fix**:
```bash
# From LAN device (should fail):
curl http://hwc-server.local:8080
# Connection refused

# From Tailscale network (should work):
curl https://hwc.ocelot-wahoo.ts.net/qbt
# qBittorrent WebUI via Caddy (Tailscale authenticated)
```

---

### 6.2 üî¥ CRITICAL: Duplicate Firewall Port Declarations

**Issue ID**: NET-2025-002
**Severity**: HIGH
**CVSS Score**: 5.0 (Medium) - Configuration complexity increases attack surface

**Description**:
Firewall ports are declared in multiple locations with inconsistent patterns, making it difficult to audit what ports are actually open and creating potential for security misconfigurations.

**Example - Jellyfin Port Declarations**:

```nix
# Declaration 1: Machine-level firewall
# Location: machines/server/config.nix:60-61
firewall.extraTcpPorts = [ 8096 7359 ];  # Jellyfin HTTP + discovery
firewall.extraUdpPorts = [ 7359 ];       # Jellyfin discovery

# Declaration 2: Native service openFirewall option
# Location: profiles/server.nix:302
hwc.server.jellyfin = {
  enable = true;
  openFirewall = false;  # Manual firewall management
};

# Declaration 3: Domain-level manual firewall
# Location: domains/server/jellyfin/index.nix:26-28
networking.firewall = lib.mkIf (!cfg.openFirewall) {
  allowedTCPPorts = [ 8096 7359 ];
  allowedUDPPorts = [ 7359 ];
};
```

**Issue**: Three different places define the same ports, creating confusion about which is active.

**Example - SLSKD Port Declarations**:

```nix
# Declaration 1: Container port binding
# Location: domains/server/containers/slskd/parts/config.nix:81-84
ports = [
  "0.0.0.0:5031:5030"
  "0.0.0.0:50300:50300/tcp"
];

# Declaration 2: Direct firewall rule
# Location: domains/server/containers/slskd/parts/config.nix:99
networking.firewall.allowedTCPPorts = [ 50300 5031 ];

# Declaration 3: Caddy auto-opens port
# Location: domains/server/containers/_shared/caddy.nix:139-141
networking.firewall.allowedTCPPorts = [80 443]
  ++ (lib.map (r: r.port) (lib.filter (r: r.mode == "port") routes));
  # ‚Üë Opens port 8443 for SLSKD Caddy route
```

**Impact**:
- Difficult to audit total attack surface
- Risk of accidentally opening duplicate ports
- Configuration drift over time
- Hard to understand firewall state without runtime inspection

**Current Firewall State** (needs runtime verification):
```bash
# To check actual open ports:
sudo nft list ruleset | grep dport
sudo ss -tulpn | grep LISTEN
```

**Recommendation**: Create centralized port registry (see Section 8.2).

---

### 6.3 ‚ö†Ô∏è WARNING: Inconsistent VPN Routing Patterns

**Issue ID**: NET-2025-003
**Severity**: MEDIUM
**CVSS Score**: 4.0 (Medium) - Maintainability issue, potential for misconfiguration

**Description**:
Two different patterns exist for VPN routing, creating inconsistency and potential for future misconfigurations.

**Pattern 1: Old Media Networking Module**
```nix
Location: domains/server/networking/parts/networking.nix:104-134

virtualisation.oci-containers.containers.gluetun = {
  # Centralized gluetun configuration
  # Used by legacy media stack
};
```

**Pattern 2: New Per-Container Network Mode**
```nix
Location: domains/server/containers/qbittorrent/options.nix

options.hwc.services.containers.qbittorrent = {
  network.mode = mkOption {
    type = types.enum [ "media" "vpn" ];
    default = "vpn";
  };
};

# Implementation: domains/server/containers/qbittorrent/parts/config.nix:36-38
extraOptions = (
  if cfg.network.mode == "vpn"
  then [ "--network=container:gluetun" ]
  else [ "--network=media-network" ]
)
```

**Containers Using Pattern 2**:
- qBittorrent
- SABnzbd
- Tdarr
- Organizr

**Issue**: Pattern 1 still partially active, creating confusion about which module controls gluetun.

**Recommendation**:
1. Fully deprecate Pattern 1 (media networking module)
2. Standardize on Pattern 2 (per-container network mode)
3. Create shared helper functions (see Section 8.3)

---

### 6.4 ‚ö†Ô∏è WARNING: Frigate tailscaleOnly Implementation Unclear

**Issue ID**: NET-2025-004
**Severity**: MEDIUM
**CVSS Score**: 4.0 (Medium) - Unclear if interface restriction is enforced

**Description**:
Frigate has a `tailscaleOnly = true` option, but the implementation may not properly restrict access to only the Tailscale interface.

**Configuration**:
```nix
# machines/server/config.nix:201
hwc.server.frigate = {
  firewall.tailscaleOnly = true;
};
```

**Implementation**:
```nix
# domains/server/frigate/parts/container.nix:194-196
interfaces."tailscale0" = lib.mkIf cfg.firewall.tailscaleOnly {
  allowedTCPPorts = [ cfg.settings.port 8554 8555 ]
    ++ lib.optionals cfg.mqtt.enable [ cfg.mqtt.port ];
};
```

**Issue**: NixOS `networking.firewall.interfaces.<name>` is additive, not restrictive. This configuration opens ports on `tailscale0`, but does NOT block them on other interfaces unless the global firewall default is deny.

**Expected Behavior**: Port 5000 should ONLY accept connections from `tailscale0`.

**Actual Behavior**: Port 5000 may be accessible from `eno1` (LAN) if global firewall allows it.

**Verification Needed**:
```bash
# Check if Frigate is accessible from LAN (should fail):
curl http://192.168.1.50:5000
```

**Recommendation**: Implement proper interface-based firewall (see Section 8.4).

---

### 6.5 ‚ö†Ô∏è WARNING: Hardcoded Tailscale Interface Name

**Issue ID**: NET-2025-005
**Severity**: LOW
**CVSS Score**: 2.0 (Low) - Edge case failure scenario

**Description**:
Firewall configuration hardcodes `tailscale0` as the Tailscale interface name. If Tailscale changes the interface naming scheme, firewall rules will silently fail.

**Hardcoded References**:
```nix
# domains/system/services/networking/index.nix:67
trustedInterfaces = [ "eno1" ] ++ (lib.optionals cfg.tailscale.enable [ "tailscale0" ]);

# domains/server/frigate/parts/container.nix:194
interfaces."tailscale0" = lib.mkIf cfg.firewall.tailscaleOnly {
  allowedTCPPorts = [ ... ];
};
```

**Risk**: If Tailscale interface becomes `tailscale1` or `ts0`, firewall rules break silently.

**Recommendation**: Detect Tailscale interface dynamically:
```nix
# Example dynamic interface detection
networking.firewall.trustedInterfaces = [ "eno1" ] ++ (
  lib.optional cfg.tailscale.enable (
    builtins.head (
      builtins.filter (iface: lib.hasPrefix "tailscale" iface)
      (builtins.attrNames config.networking.interfaces)
    )
  )
);
```

---

### 6.6 ‚úÖ GOOD: Proper VPN Enforcement

**No Issue - Documented for Completeness**

**Description**:
Despite the port exposure issues, the VPN routing itself is implemented correctly and securely.

**Security Properties**:

1. **Network Namespace Isolation**:
   ```nix
   # qBittorrent and SABnzbd have NO network access except through gluetun
   extraOptions = [ "--network=container:gluetun" ];
   ```

2. **No Direct Internet Access**:
   - Containers cannot create sockets in host network namespace
   - All traffic must traverse gluetun's network stack
   - VPN tunnel is the ONLY route to internet

3. **Built-in Kill Switch**:
   - If VPN disconnects, gluetun container has no internet
   - Dependent containers (qBittorrent, SABnzbd) automatically lose connectivity
   - No need for additional kill-switch configuration

4. **Credential Security**:
   ```nix
   # VPN credentials encrypted with agenix
   VPN_USERNAME=$(cat ${config.age.secrets.vpn-username.path})
   VPN_PASSWORD=$(cat ${config.age.secrets.vpn-password.path})
   ```

5. **Health Monitoring**:
   ```nix
   # Systemd timer checks VPN health every 5 minutes
   systemd.timers.gluetun-health-check = {
     timerConfig.OnCalendar = "*:0/5";
   };
   ```

**Verification Commands**:
```bash
# Check VPN tunnel is active
podman exec gluetun ip addr show tun0

# Verify VPN IP (should be Netherlands)
podman exec gluetun wget -qO- https://api.ipify.org

# Confirm qBittorrent uses VPN IP (should match above)
podman exec qbittorrent wget -qO- https://api.ipify.org
```

**Security Rating**: ‚úÖ Excellent

---

## 7. FIREWALL RULE AUDIT

### 7.1 Server Firewall (Level: "server")

**Configuration Location**: machines/server/config.nix:59

**Auto-Opened Ports** (from firewall level):
```nix
# domains/system/services/networking/index.nix:60-66
allowedTCPPorts =
  cfg.firewall.extraTcpPorts
  ++ (lib.optionals (cfg.firewall.level == "server") [ 80 443 ])
  ++ (lib.optionals cfg.ssh.enable [ cfg.ssh.port ])
  ++ (lib.optionals cfg.samba.enable [ 139 445 ]);
```

**Resolved Ports**:
- **22** (SSH)
- **80** (HTTP - from level="server")
- **443** (HTTPS - from level="server")

**Extra TCP Ports** (machines/server/config.nix:60):
- **8096** (Jellyfin HTTP)
- **7359** (Jellyfin TCP discovery)
- **2283** (Immich)
- **4533** (Navidrome)

**Extra UDP Ports** (machines/server/config.nix:61):
- **7359** (Jellyfin UDP discovery)

**Caddy Auto-Opened Ports** (domains/server/containers/_shared/caddy.nix:139-141):
- **5543** (Jellyseerr)
- **7443** (Immich)
- **5443** (Frigate)
- **8443** (SLSKD)
- **8267** (Tdarr)
- **9443** (Organizr)

**Container-Opened Ports** (domains/server/containers/slskd/parts/config.nix:99):
- **50300** (SLSKD P2P)
- **5031** (SLSKD WebUI - should be removed)

**Trusted Interfaces** (bypass firewall):
- **eno1** (LAN - physical interface)
- **tailscale0** (Tailscale mesh VPN)

### 7.2 Total Attack Surface (TCP)

```
Port    Service         Bind Address    Accessible From         Risk
----    -------         ------------    ---------------         ----
22      SSH             0.0.0.0         LAN, Tailscale         Medium (auth required)
80      HTTP            Tailscale?      Tailscale              Low (redirects to 443)
443     HTTPS           Tailscale?      Tailscale              Low (Caddy TLS)
2283    Immich          127.0.0.1       Localhost only         Low
4533    Navidrome       ?               Needs verification     Medium
5031    SLSKD WebUI     0.0.0.0         LAN, Tailscale         HIGH üî¥
5443    Frigate (Caddy) Tailscale       Tailscale              Low
5543    Jellyseerr      Tailscale       Tailscale              Low
7359    Jellyfin Disc   ?               Needs verification     Medium
7443    Immich (Caddy)  Tailscale       Tailscale              Low
8080    qBittorrent     0.0.0.0         LAN, Tailscale         HIGH üî¥
8081    SABnzbd         0.0.0.0         LAN, Tailscale         HIGH üî¥
8096    Jellyfin        ?               Needs verification     Medium
8267    Tdarr (Caddy)   Tailscale       Tailscale              Low
8443    SLSKD (Caddy)   Tailscale       Tailscale              Low
9443    Organizr        Tailscale       Tailscale              Low
50300   SLSKD P2P       0.0.0.0         Internet (required)    Medium
```

**Notes**:
- Ports marked with `?` need runtime verification to determine actual bind address
- Caddy ports (with reverse proxy) are assumed to bind to Tailscale IP only
- Ports bound to `127.0.0.1` are only accessible via Caddy reverse proxy

### 7.3 Laptop Firewall (Level: "strict")

**Configuration Location**: machines/laptop/config.nix:121

**Auto-Opened Ports**:
- **22** (SSH)

**Extra Ports**: None

**Security Posture**: ‚úÖ Excellent - minimal attack surface

---

## 8. RECOMMENDED IMPROVEMENTS

### 8.1 Priority 1: Fix 0.0.0.0 Bindings üî¥

**Urgency**: IMMEDIATE (critical security issue)

**Files to Modify**:

#### File 1: domains/server/containers/gluetun/parts/config.nix
```diff
@@ -46,8 +46,8 @@
     "--privileged"
   ];
   ports = [
-    "0.0.0.0:8080:8080"  # qBittorrent UI
-    "0.0.0.0:8081:8085"  # SABnzbd (container uses 8085 internally)
+    "127.0.0.1:8080:8080"  # qBittorrent UI (Caddy proxied at /qbt)
+    "127.0.0.1:8081:8085"  # SABnzbd UI (Caddy proxied at /sab)
   ];
   volumes = [ "${cfgRoot}/gluetun:/gluetun" ];
   environmentFiles = [ "${cfgRoot}/.env" ];
```

#### File 2: domains/server/containers/slskd/parts/config.nix
```diff
@@ -80,7 +80,7 @@
     cmd = [ "--config" "/app/slskd.yml" ];
     ports = [
-      "0.0.0.0:5031:5030"        # Web UI - SLSKD requires dedicated port
+      "127.0.0.1:5031:5030"      # Web UI (Caddy proxied at :8443)
       "0.0.0.0:50300:50300/tcp"  # P2P port
     ];
     volumes = [
@@ -96,7 +96,7 @@
   };

   # Firewall configuration - SLSKD requires dedicated port
-  networking.firewall.allowedTCPPorts = [ 50300 5031 ];
+  networking.firewall.allowedTCPPorts = [ 50300 ];  # P2P only; WebUI via Caddy

   # Service dependencies
   systemd.services."podman-slskd".after = [ "network-online.target" "init-media-network.service" "slskd-config-generator.service" ];
```

#### File 3: domains/server/containers/jellyfin/sys.nix
```diff
@@ -13,7 +13,7 @@
       networkMode = "media";
       gpuMode = "intel";  # Static default - GPU detection deferred
       timeZone = "UTC";   # Static default - timezone detection deferred
-      ports = [ "0.0.0.0:8096:8096" ];
+      ports = [ "127.0.0.1:8096:8096" ];  # Only if container re-enabled
       volumes = [ "/opt/downloads/jellyfin:/config" ];
       environment = { };
     };
```

**Testing After Changes**:
```bash
# Rebuild NixOS configuration
sudo nixos-rebuild switch

# Verify ports are NOT accessible from LAN
curl http://192.168.1.50:8080  # Should fail (connection refused)
curl http://192.168.1.50:8081  # Should fail (connection refused)
curl http://192.168.1.50:5031  # Should fail (connection refused)

# Verify ports ARE accessible via Tailscale + Caddy
curl https://hwc.ocelot-wahoo.ts.net/qbt  # Should work
curl https://hwc.ocelot-wahoo.ts.net/sab  # Should work
curl https://hwc.ocelot-wahoo.ts.net:8443 # Should work (SLSKD)
```

---

### 8.2 Priority 2: Create Centralized Port Registry üü°

**Urgency**: HIGH (improves maintainability and security audit)

**New File**: domains/networking/ports.nix
```nix
# HWC Port Allocation Registry
# Single source of truth for all network ports
{ lib, ... }:
{
  # Port allocation manifest
  hwc.networking.ports = {
    # System Services
    system = {
      ssh = {
        port = 22;
        protocol = "tcp";
        interfaces = [ "all" ];
        description = "OpenSSH daemon";
      };
      http = {
        port = 80;
        protocol = "tcp";
        interfaces = [ "tailscale0" ];
        description = "Caddy HTTP (redirects to HTTPS)";
      };
      https = {
        port = 443;
        protocol = "tcp";
        interfaces = [ "tailscale0" ];
        description = "Caddy HTTPS";
      };
    };

    # Native Media Services
    media = {
      jellyfin = {
        http = { port = 8096; protocol = "tcp"; interfaces = [ "tailscale0" ]; };
        discovery = { port = 7359; protocol = [ "tcp" "udp" ]; interfaces = [ "tailscale0" ]; };
      };
      immich = {
        port = 2283;
        protocol = "tcp";
        bindAddress = "127.0.0.1";
        description = "Immich photo management (proxied via Caddy)";
      };
      navidrome = {
        port = 4533;
        protocol = "tcp";
        bindAddress = "127.0.0.1";
        description = "Navidrome music server (proxied via Caddy /music)";
      };
      couchdb = {
        port = 5984;
        protocol = "tcp";
        bindAddress = "127.0.0.1";
        description = "CouchDB for Obsidian LiveSync (proxied via Caddy /sync)";
      };
      frigate = {
        port = 5000;
        protocol = "tcp";
        interfaces = [ "tailscale0" ];
        description = "Frigate NVR (Tailscale-only access)";
      };
    };

    # Caddy Reverse Proxy Ports (dedicated TLS listeners)
    caddy = {
      jellyseerr = { port = 5543; upstream = "127.0.0.1:5055"; };
      immich = { port = 7443; upstream = "127.0.0.1:2283"; };
      frigate = { port = 5443; upstream = "127.0.0.1:5000"; };
      slskd = { port = 8443; upstream = "127.0.0.1:5031"; };
      tdarr = { port = 8267; upstream = "127.0.0.1:8265"; };
      organizr = { port = 9443; upstream = "127.0.0.1:9983"; };
    };

    # Download Clients (localhost-only, Caddy subpaths)
    downloaders = {
      qbittorrent = {
        port = 8080;
        bindAddress = "127.0.0.1";
        caddyPath = "/qbt";
        vpnRouted = true;
      };
      sabnzbd = {
        port = 8081;
        bindAddress = "127.0.0.1";
        caddyPath = "/sab";
        vpnRouted = true;
      };
    };

    # P2P Services (must be publicly accessible)
    p2p = {
      slskd = {
        port = 50300;
        protocol = "tcp";
        interfaces = [ "all" ];
        description = "SLSKD Soulseek P2P (required for peer connections)";
      };
    };

    # Arr Stack (localhost-only, Caddy subpaths)
    arr = {
      sonarr = { port = 8989; bindAddress = "127.0.0.1"; caddyPath = "/sonarr"; };
      radarr = { port = 7878; bindAddress = "127.0.0.1"; caddyPath = "/radarr"; };
      lidarr = { port = 8686; bindAddress = "127.0.0.1"; caddyPath = "/lidarr"; };
      prowlarr = { port = 9696; bindAddress = "127.0.0.1"; caddyPath = "/prowlarr"; };
    };
  };

  # Helper function to generate firewall rules from port registry
  hwc.networking.ports.toFirewallRules = portRegistry: {
    allowedTCPPorts = lib.flatten (
      lib.mapAttrsToList (category: services:
        lib.mapAttrsToList (name: config:
          lib.optional
            (config.interfaces or [] == [ "all" ] && config.protocol or "tcp" == "tcp")
            config.port
        ) services
      ) portRegistry
    );
    # Similar for UDP, per-interface rules, etc.
  };
}
```

**Usage in Machine Configs**:
```nix
# machines/server/config.nix
{
  imports = [ ../../domains/networking/ports.nix ];

  # Firewall rules auto-generated from port registry
  hwc.networking.firewall = hwc.networking.ports.toFirewallRules config.hwc.networking.ports;
}
```

---

### 8.3 Priority 3: Standardize Container Network Helpers üü°

**Urgency**: MEDIUM (improves consistency)

**New File**: domains/server/containers/_shared/network-helpers.nix
```nix
# Standard network configuration helpers for containers
{ lib }:
{
  # VPN-routed container (shares gluetun network namespace)
  mkVpnContainer = { name }: {
    extraOptions = [ "--network=container:gluetun" ];
    ports = [];  # Ports exposed by gluetun, not directly
    dependsOn = [ "gluetun" ];
  };

  # Media network container with localhost-only port
  mkMediaContainer = { port }: {
    extraOptions = [ "--network=media-network" ];
    ports = [ "127.0.0.1:${toString port}:${toString port}" ];
  };

  # Tailscale-only service (public port but interface-restricted)
  mkTailscaleContainer = { port }: {
    extraOptions = [ "--network=media-network" ];
    ports = [ "0.0.0.0:${toString port}:${toString port}" ];
    # NOTE: Firewall should restrict to tailscale0 interface
  };

  # P2P service (must be publicly accessible)
  mkPublicContainer = { port }: {
    extraOptions = [ "--network=media-network" ];
    ports = [ "0.0.0.0:${toString port}:${toString port}" ];
  };

  # Helper to build complete container network config
  mkContainerNetwork = { mode, port ? null, publicPort ? false }:
    if mode == "vpn" then mkVpnContainer { name = "container"; }
    else if port != null && publicPort then mkPublicContainer { inherit port; }
    else if port != null then mkMediaContainer { inherit port; }
    else { extraOptions = [ "--network=media-network" ]; ports = []; };
}
```

**Usage in Container Configs**:
```nix
# domains/server/containers/qbittorrent/parts/config.nix
{ lib, config, pkgs, ... }:
let
  cfg = config.hwc.services.containers.qbittorrent;
  networkHelpers = import ../../_shared/network-helpers.nix { inherit lib; };
in {
  config = lib.mkIf cfg.enable {
    virtualisation.oci-containers.containers.qbittorrent = {
      image = cfg.image;
      autoStart = true;

      # Use standard network helper
      inherit (networkHelpers.mkVpnContainer { name = "qbittorrent"; })
        extraOptions ports dependsOn;

      # ... rest of config
    };
  };
}
```

---

### 8.4 Priority 4: Implement Interface-Based Firewall üü°

**Urgency**: MEDIUM (improves security granularity)

**Enhanced Firewall Module**: domains/system/services/networking/firewall.nix
```nix
{ config, lib, pkgs, ... }:
let
  cfg = config.hwc.networking.firewall;
in {
  options.hwc.networking.firewall = {
    # ... existing options (level, extraTcpPorts, extraUdpPorts) ...

    # New: Per-interface rules
    interfaceRules = lib.mkOption {
      type = lib.types.attrsOf (lib.types.submodule {
        options = {
          allowedTCPPorts = lib.mkOption {
            type = lib.types.listOf lib.types.port;
            default = [];
            description = "TCP ports to allow on this interface";
          };
          allowedUDPPorts = lib.mkOption {
            type = lib.types.listOf lib.types.port;
            default = [];
            description = "UDP ports to allow on this interface";
          };
          trustedTraffic = lib.mkOption {
            type = lib.types.bool;
            default = false;
            description = "Allow all traffic on this interface";
          };
        };
      });
      default = {};
      example = {
        "tailscale0" = {
          allowedTCPPorts = [ 8096 5000 443 ];
          trustedTraffic = false;
        };
        "eno1" = {
          allowedTCPPorts = [ 50300 ];  # Only P2P ports
          trustedTraffic = false;
        };
      };
      description = "Firewall rules per network interface";
    };
  };

  config = lib.mkIf cfg.enable {
    # Global firewall rules (apply to all interfaces)
    networking.firewall = {
      enable = cfg.level != "off";
      allowPing = cfg.level == "basic";
      allowedTCPPorts = cfg.extraTcpPorts
        ++ lib.optionals (cfg.level == "server") [ 80 443 ]
        ++ lib.optionals cfg.ssh.enable [ cfg.ssh.port ];
      allowedUDPPorts = cfg.extraUdpPorts;
    };

    # Per-interface rules (more restrictive)
    networking.firewall.interfaces = lib.mapAttrs (iface: rules:
      if rules.trustedTraffic then {
        # Trusted interface - allow all
        allowedTCPPorts = [];
        allowedUDPPorts = [];
      } else {
        # Restricted interface - explicit ports only
        allowedTCPPorts = rules.allowedTCPPorts;
        allowedUDPPorts = rules.allowedUDPPorts;
      }
    ) cfg.interfaceRules;

    # Trusted interfaces (old behavior for compatibility)
    networking.firewall.trustedInterfaces = lib.mapAttrsToList
      (iface: rules: iface)
      (lib.filterAttrs (_: rules: rules.trustedTraffic) cfg.interfaceRules);
  };
}
```

**Usage Example**:
```nix
# machines/server/config.nix
hwc.networking.firewall = {
  level = "server";

  # Per-interface rules
  interfaceRules = {
    "tailscale0" = {
      # Tailscale mesh - allow media services
      allowedTCPPorts = [ 8096 7359 5000 2283 4533 ];
      allowedUDPPorts = [ 7359 ];
      trustedTraffic = false;  # Explicit allow, not blanket trust
    };
    "eno1" = {
      # LAN - only allow P2P ports, deny everything else
      allowedTCPPorts = [ 50300 ];  # SLSKD P2P only
      trustedTraffic = false;
    };
  };
};
```

---

### 8.5 Priority 5: Declarative Gluetun VPN Routing üü¢

**Urgency**: LOW (enhancement, current system works)

**New Module**: domains/server/downloaders/vpn-routing.nix
```nix
# Declarative VPN routing for download clients
{ config, lib, pkgs, ... }:
let
  cfg = config.hwc.downloaders.vpn;
in {
  options.hwc.downloaders.vpn = {
    enable = lib.mkEnableOption "VPN routing for download clients";

    provider = lib.mkOption {
      type = lib.types.enum [ "protonvpn" "mullvad" "nordvpn" ];
      default = "protonvpn";
      description = "VPN provider";
    };

    serverCountries = lib.mkOption {
      type = lib.types.listOf lib.types.str;
      default = [ "Netherlands" ];
      description = "VPN server countries";
    };

    routes = lib.mkOption {
      type = lib.types.listOf (lib.types.submodule {
        options = {
          name = lib.mkOption { type = lib.types.str; };
          internalPort = lib.mkOption { type = lib.types.port; };
          externalPort = lib.mkOption { type = lib.types.port; };
          bindAddress = lib.mkOption {
            type = lib.types.str;
            default = "127.0.0.1";
            description = "Bind address for port forwarding";
          };
        };
      });
      default = [
        { name = "qbittorrent"; internalPort = 8080; externalPort = 8080; }
        { name = "sabnzbd"; internalPort = 8085; externalPort = 8081; }
      ];
      description = "Services to route through VPN with port forwarding";
    };
  };

  config = lib.mkIf cfg.enable {
    # Gluetun container with declarative configuration
    virtualisation.oci-containers.containers.gluetun = {
      image = "qmcgaw/gluetun:latest";
      autoStart = true;
      extraOptions = [
        "--cap-add=NET_ADMIN"
        "--device=/dev/net/tun:/dev/net/tun"
        "--network=media-network"
        "--privileged"
      ];

      # Port forwarding from routes
      ports = map (route:
        "${route.bindAddress}:${toString route.externalPort}:${toString route.internalPort}"
      ) cfg.routes;

      environment = {
        VPN_SERVICE_PROVIDER = cfg.provider;
        VPN_TYPE = "openvpn";
        SERVER_COUNTRIES = lib.concatStringsSep "," cfg.serverCountries;
        HEALTH_VPN_DURATION_INITIAL = "30s";
        TZ = config.time.timeZone or "America/Denver";
      };

      environmentFiles = [ "/run/agenix/vpn-credentials" ];
    };

    # Health monitoring
    systemd.timers.gluetun-health-check = {
      wantedBy = [ "timers.target" ];
      timerConfig.OnCalendar = "*:0/5";
    };
  };
}
```

**Usage**:
```nix
# profiles/server.nix
hwc.downloaders.vpn = {
  enable = true;
  provider = "protonvpn";
  serverCountries = [ "Netherlands" "Switzerland" ];
  routes = [
    { name = "qbittorrent"; internalPort = 8080; externalPort = 8080; bindAddress = "127.0.0.1"; }
    { name = "sabnzbd"; internalPort = 8085; externalPort = 8081; bindAddress = "127.0.0.1"; }
  ];
};

# Containers declare VPN dependency
hwc.services.containers.qbittorrent = {
  enable = true;
  network.mode = "vpn";  # Automatically uses container:gluetun
};
```

---

## 9. IMPLEMENTATION ROADMAP

### Phase 1: Critical Security Fixes (Week 1)
- ‚úÖ Fix 0.0.0.0 bindings (Priority 1)
- ‚úÖ Test Caddy reverse proxy still works
- ‚úÖ Verify VPN routing unaffected
- ‚úÖ Document changes in changelog

### Phase 2: Port Registry (Week 2)
- Create domains/networking/ports.nix
- Migrate firewall rules to use registry
- Update documentation
- Create audit script to verify actual vs. declared ports

### Phase 3: Network Standardization (Week 3-4)
- Implement network-helpers.nix
- Migrate containers to use helpers
- Deprecate old media networking module
- Update container documentation

### Phase 4: Enhanced Firewall (Week 5)
- Implement interface-based firewall module
- Migrate server to use per-interface rules
- Test Tailscale-only restrictions
- Document new firewall patterns

### Phase 5: VPN Routing Abstraction (Week 6)
- Create declarative VPN routing module
- Migrate gluetun configuration
- Test with multiple download clients
- Document VPN routing patterns

---

## 10. MONITORING AND VALIDATION

### 10.1 Runtime Verification Commands

**Check Open Ports**:
```bash
# List all listening TCP ports
sudo ss -tulpn | grep LISTEN

# Check firewall rules
sudo nft list ruleset | grep dport

# Verify Tailscale interface
ip addr show tailscale0
```

**Verify Container Networking**:
```bash
# Check qBittorrent network mode
podman inspect qbittorrent | jq '.[0].HostConfig.NetworkMode'
# Expected: "container:<gluetun-id>"

# Check VPN IP
podman exec gluetun wget -qO- https://api.ipify.org
# Expected: VPN exit IP (Netherlands)

# Verify qBittorrent uses VPN
podman exec qbittorrent wget -qO- https://api.ipify.org
# Expected: Same as gluetun IP
```

**Test Access Controls**:
```bash
# From LAN device (should fail after fixes):
curl http://hwc-server.local:8080
curl http://hwc-server.local:8081
curl http://hwc-server.local:5031

# From Tailscale network (should work):
curl https://hwc.ocelot-wahoo.ts.net/qbt
curl https://hwc.ocelot-wahoo.ts.net/sab
curl https://hwc.ocelot-wahoo.ts.net:8443
```

### 10.2 Automated Security Scanning

**Create Port Scan Script**:
```bash
#!/usr/bin/env bash
# File: workspace/scripts/network-security-scan.sh

echo "=== HWC Network Security Scan ==="
echo "Scanning server: hwc-server.local"
echo

# Check for unsafe 0.0.0.0 bindings
echo "Checking for unsafe port bindings..."
nmap -p 8080,8081,5031,8096 hwc-server.local

# Verify Tailscale-only services are NOT accessible from LAN
echo
echo "Verifying Tailscale-only services..."
timeout 2 curl -s http://hwc-server.local:5443 && echo "‚ö†Ô∏è  Frigate accessible from LAN!" || echo "‚úÖ Frigate NOT accessible from LAN"
timeout 2 curl -s http://hwc-server.local:7443 && echo "‚ö†Ô∏è  Immich accessible from LAN!" || echo "‚úÖ Immich NOT accessible from LAN"

# Check VPN is active
echo
echo "Verifying VPN status..."
podman exec gluetun wget -qO- https://api.ipify.org
```

### 10.3 Continuous Monitoring

**Systemd Timer for Regular Scans**:
```nix
systemd.services.network-security-scan = {
  description = "Network security scan";
  serviceConfig.Type = "oneshot";
  script = "${pkgs.bash}/bin/bash /path/to/network-security-scan.sh";
};

systemd.timers.network-security-scan = {
  wantedBy = [ "timers.target" ];
  timerConfig.OnCalendar = "daily";
};
```

---

## 11. CONCLUSION

### Summary of Findings

**Critical Issues**: 4
- 0.0.0.0 port bindings exposing download clients and admin interfaces to LAN
- Duplicate firewall declarations creating confusion
- Inconsistent VPN routing patterns
- Unclear Tailscale-only interface restrictions

**Warnings**: 3
- No centralized port registry
- Hardcoded Tailscale interface name
- Missing runtime validation

**Good Practices**: 5
- Proper VPN enforcement via namespace sharing
- Correct Tailscale integration with certificate support
- Safe localhost bindings for most services
- Encrypted credential storage via agenix
- VPN health monitoring

### Risk Assessment

**Overall Security Posture**: MEDIUM-HIGH RISK

**Immediate Threats**:
- Download client web UIs accessible without authentication from LAN
- Admin interfaces (SLSKD) exposed to local network
- Potential for accidental service exposure due to configuration complexity

**Mitigating Factors**:
- VPN routing works correctly (traffic properly isolated)
- Most services correctly bound to localhost
- Tailscale provides authentication for remote access
- Firewall is enabled and mostly configured correctly

### Next Steps

1. **Immediate**: Apply Priority 1 fixes (0.0.0.0 bindings)
2. **Short-term**: Implement port registry (Priority 2)
3. **Medium-term**: Standardize network helpers (Priority 3)
4. **Long-term**: Enhanced firewall and VPN abstraction (Priority 4-5)

### Appendix: Files Modified Summary

```
Priority 1 (Critical):
  domains/server/containers/gluetun/parts/config.nix
  domains/server/containers/slskd/parts/config.nix
  domains/server/containers/jellyfin/sys.nix

Priority 2 (Port Registry):
  domains/networking/ports.nix (new)
  machines/server/config.nix (update firewall)

Priority 3 (Network Helpers):
  domains/server/containers/_shared/network-helpers.nix (new)
  domains/server/containers/*/parts/config.nix (migrate to helpers)

Priority 4 (Interface Firewall):
  domains/system/services/networking/firewall.nix (enhance)
  machines/server/config.nix (add interface rules)

Priority 5 (VPN Routing):
  domains/server/downloaders/vpn-routing.nix (new)
  profiles/server.nix (use declarative VPN routing)
```

---

**End of Report**

# Infrastructure Domain

## Purpose & Scope

The **Infrastructure Domain** provides integration glue between users, hardware, and services. It implements the "wiring layer" that connects different parts of the system without implementing core functionality itself.

**Key Principle**: If it owns a daemon â†’ system/services domain. If it enforces policy â†’ security domain. **If it wires users/services to hardware or to each other â†’ infrastructure domain**.

## 3-Bucket Architecture

Infrastructure is organized into exactly **3 clean buckets** to eliminate sprawl:

### ğŸ”§ Hardware Bucket (`hardware/`)
**User â†” Hardware integration glue**
- **GPU acceleration**: Provides `hwc.infrastructure.hardware.gpu.*` for GPU detection, driver integration, container runtime support
- **Permissions**: User groups and hardware ACLs (`hwc.infrastructure.hardware.permissions.*`)
- **Peripherals**: Printer integration glue (`hwc.infrastructure.hardware.peripherals.*`)
- **Storage**: Storage device integration and mount helpers (`hwc.infrastructure.hardware.storage.*`)

### ğŸŒ Mesh Bucket (`mesh/`)
**Service â†” Service and Service â†” Network glue**
- **Container networking**: Inter-container communication, network overlays
- Future: Service mesh, load balancing, service discovery glue

### ğŸ‘¤ Session Bucket (`session/`)
**User-scoped helpers (non-WM-specific)**
- **Background services**: User environment setup, SSH key management
- **Shared commands**: CLI tools for cross-app integration (gpu-launch, etc.)
- **App system integration**: System-side helpers for HM apps (dbus, portals, dconf)

## Option Namespace Convention

All infrastructure options follow the pattern:
```nix
hwc.infrastructure.<bucket>.<module>.*
```

Examples:
- `hwc.infrastructure.hardware.gpu.enable = true;`
- `hwc.infrastructure.hardware.permissions.groups.media = true;`
- `hwc.infrastructure.session.chromium.enable = true;`
- `hwc.infrastructure.mesh.containerNetworking.enable = true;`

## Data Flow & Integration Points

### GPU Pipeline Example
```
Machine Config â†’ hwc.infrastructure.hardware.gpu.type = "nvidia"
       â†“
GPU Module â†’ Detects drivers, configures runtime
       â†“
Services â†’ config.hwc.infrastructure.hardware.gpu.accel (consumed by ollama, jellyfin)
       â†“
User Apps â†’ gpu-launch command available for HM keybinds
```

### App Integration Pipeline (Chromium Example)
```
profiles/hm.nix â†’ features.chromium.enable = true (HM package)
       â†“
modules/home/apps/chromium/index.nix â†’ home.packages = [ chromium ]
       â†“
profiles/workstation.nix â†’ hwc.infrastructure.session.chromium.enable = true
       â†“
modules/home/apps/chromium/sys.nix â†’ programs.dconf.enable, services.dbus.enable
       â†“
User Session â†’ chromium binary available, system integration working
       â†“
gpu-launch chromium â†’ Works via user PATH + GPU acceleration
```

## File Structure

```
modules/infrastructure/
â”œâ”€â”€ index.nix                    # Domain aggregator (imports 3 buckets)
â”‚
â”œâ”€â”€ hardware/                    # Hardware integration bucket
â”‚   â”œâ”€â”€ gpu.nix                 # GPU acceleration & driver integration
â”‚   â”œâ”€â”€ permissions.nix         # User groups & hardware ACLs  
â”‚   â”œâ”€â”€ peripherals.nix         # Printer/scanner integration glue
â”‚   â””â”€â”€ storage.nix             # Storage device integration
â”‚
â”œâ”€â”€ mesh/                       # Service networking bucket
â”‚   â””â”€â”€ container-networking.nix # Container network integration
â”‚
â””â”€â”€ session/                    # User session bucket
    â”œâ”€â”€ services.nix            # Background user services
    â””â”€â”€ commands.nix            # Shared CLI commands (disabled by default)
```

## Import Pattern

Profiles should import the domain aggregator, not individual modules:

```nix
# âœ… Correct - Clean aggregation
imports = [ ../modules/infrastructure ];

# âŒ Wrong - Bypasses domain boundaries  
imports = [
  ../modules/infrastructure/hardware/gpu.nix
  ../modules/infrastructure/session/services.nix
];
```

## Validation Rules

1. **No daemon ownership**: Infrastructure modules configure but don't own systemd services
2. **No business logic**: Pure integration glue, no application-specific behavior  
3. **Stable interfaces**: Other domains should consume via stable option paths
4. **3-bucket limit**: All functionality must fit within hardware/mesh/session buckets
5. **Namespace consistency**: All options under `hwc.infrastructure.<bucket>.<module>.*`

## Common Usage Patterns

### Enable GPU acceleration for services
```nix
# Machine declares hardware reality
hwc.infrastructure.hardware.gpu = {
  enable = true;
  type = "nvidia";
  nvidia.containerRuntime = true;
};

# Services automatically consume via config.hwc.infrastructure.hardware.gpu.accel
```

### Add user to hardware groups
```nix
hwc.infrastructure.hardware.permissions = {
  enable = true;
  groups = {
    media = true;        # audio/video device access
    hardware = true;     # GPIO, sensors, etc.
    development = true;  # USB devices, debuggers
  };
};
```

### Enable system integration for HM app
```nix
# HM side: features.chromium.enable = true (in profiles/hm.nix)
# System side:
hwc.infrastructure.session.chromium.enable = true;  # dbus, dconf, portals
```

## Anti-Patterns to Avoid

- **âŒ Hardware modules in home/**: Violates domain separation
- **âŒ Service implementation**: Infrastructure provides glue, not services
- **âŒ Complex business logic**: Keep modules simple and focused
- **âŒ Cross-bucket dependencies**: Buckets should be independent
- **âŒ Direct service configuration**: Use stable option interfaces

## Troubleshooting

**GPU not working in containers?**
- Check `hwc.infrastructure.hardware.gpu.nvidia.containerRuntime = true`
- Verify `config.hwc.infrastructure.hardware.gpu.accel` is set correctly

**User can't access hardware?** 
- Check `hwc.infrastructure.hardware.permissions.groups.*` settings
- Verify user is in the expected groups via `groups` command

**App missing system integration?**
- Check if `hwc.infrastructure.session.<app>.enable = true` is set
- Verify the app's `sys.nix` file is being imported via `profiles/sys.nix`

---

The infrastructure domain provides the essential "glue code" that makes the system cohesive without creating tight coupling between domains. Keep it focused on integration, not implementation.